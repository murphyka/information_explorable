Notebooks for [Do Machine Learning Models Memorize or Generalize?](https://pair.withgoogle.com/explorables/grokking/)

- [MLP Modular Addition](https://colab.research.google.com/github/PAIR-code/ai-explorables/blob/master/server-side/grokking/MLP_Modular_Addition.ipynb) — Main model used throughout the post
- [MLP Sparse Parity](https://colab.research.google.com/github/PAIR-code/ai-explorables/blob/master/server-side/grokking/MLP_Sparse_Parity.ipynb) — The 1s and 0s task
- [MLP Modular Addition Fixed Embed](https://colab.research.google.com/github/PAIR-code/ai-explorables/blob/master/server-side/grokking/MLP_Modular_Addition_Fixed_Embed.ipynb) — Freeze W_embed to a circle and train a very small model 